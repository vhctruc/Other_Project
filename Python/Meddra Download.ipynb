{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bdf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dic_reading.py\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "# se_dic = pickle.load(open('../Data/curated/AE_dic.pk', 'rb'))\n",
    "# drug_dic = pickle.load(open('../Data/curated/drug_mapping.pk', 'rb'))\n",
    "\n",
    "# # In this MeDRA_dic, key is string of PT_name, value is a list:\n",
    "# # [PT, PT_name, HLT,HLT_name,HLGT,HLGT_name,SOC,SOC_name,SOC_abbr]\n",
    "# meddra_pd_all = pickle.load(open('../Data/curated/AE_mapping.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48de6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "def date_normalize(formate, dat): \n",
    "    stand_date = date(2000, 1, 1)\n",
    "    if formate=='102':  # the date is formed as yyyymmdd\n",
    "        current_date = date(int(dat[:4]), int(dat[4:6]), int(dat[6:8])) \n",
    "    elif formate=='610':  # formed as yyyymm\n",
    "        current_date = date(int(dat[:4]), int(dat[4:6]), 1)\n",
    "    elif formate=='602':  #formed as yyyy\n",
    "        current_date = date(int(dat[:4]), 1, 1)\n",
    "    delta = current_date - stand_date\n",
    "    return delta.days\n",
    "\n",
    "def days_to_date(days):\n",
    "    stand_date = date(2000, 1, 1)\n",
    "\n",
    "    if int(days)<0:\n",
    "        days = 1\n",
    "    \n",
    "    dt = datetime.fromordinal(int(days))\n",
    "    return dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd60ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am parsing: 2013q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2013q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2013q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2013q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2014q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2014q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2014q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2014q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2015q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2015q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2015q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2015q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2016q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2016q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2016q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2016q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2017q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2017q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2017q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2017q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2018q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2018q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2018q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2018q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2019q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2019q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2019q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2019q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2020q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2020q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2020q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2021q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2021q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2021q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2021q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2022q1\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2022q2\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2022q3\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n",
      "I am parsing: 2022q4\n",
      "find 1 files\n",
      "['D:/Medra/faers_xml_2022Q4/TEST\\\\2022q4.xml']\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "def date_normalize(formate, dat): \n",
    "    stand_date = date(2000, 1, 1)\n",
    "    if formate=='102':  # the date is formed as yyyymmdd\n",
    "        current_date = date(int(dat[:4]), int(dat[4:6]), int(dat[6:8])) \n",
    "    elif formate=='610':  # formed as yyyymm  \n",
    "        current_date = date(int(dat[:4]), int(dat[4:6]), 1)\n",
    "    elif formate=='602':  #formed as yyyy      \n",
    "        current_date = date(int(dat[:4]), 1, 1)\n",
    "    delta = current_date - stand_date\n",
    "    return delta.days\n",
    "\n",
    "n_reports = []\n",
    "miss_count = {}\n",
    "# To save time, parse 2018-2018  in the first round, then 2018-2021\n",
    "for yr in range(2013, 2023):\n",
    "\n",
    "    if yr == 2020:\n",
    "        qtr_list = [1, 2, 3]\n",
    "#         qtr_list = [3]\n",
    "    else:\n",
    "        qtr_list=[1,2,3,4]\n",
    "    for qtr in qtr_list:\n",
    "        qtr_name = str(yr)+'q'+ str(qtr)\n",
    "        print('I am parsing:',qtr_name)\n",
    "        \n",
    "#         \"\"\"Read data from lab storage\"\"\" \n",
    "#         /n/data1/hms/dbmi/zitnik/lab/datasets/2020-08-FAERS/\n",
    "        lab_storage = 'D:/Medra/faers_xml_2022Q4/TEST'\n",
    "\n",
    "#         files = lab_storage + qtr_name + '/**/**'\n",
    "        xml_files = glob.glob(lab_storage +\"/*.xml\", recursive=True)\n",
    "        unique_files = list(set(xml_files))  # only keep the unique values, remove duplicated files.\n",
    "        xml_files = unique_files\n",
    "        xml_files.sort()\n",
    "        print('find {} files'.format(len(xml_files)))\n",
    "        print(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630db46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Medra/faers_xml_2022Q4/TEST\\2022q4.xml\n",
      "150103\n"
     ]
    }
   ],
   "source": [
    "        root = None\n",
    "        for xml_file in xml_files:\n",
    "            print(xml_file)\n",
    "            data = ET.parse(xml_file).getroot()\n",
    "            if root is None:\n",
    "                root = data\n",
    "            else:\n",
    "                root.extend(data)\n",
    "                print('finished merge',xml_file)\n",
    "        nmb_reports = len(root)\n",
    "        print(nmb_reports)\n",
    "\n",
    "        count = 0\n",
    "        patient_ID = 0\n",
    "        dic = {}\n",
    "        \n",
    "        miss_admin = miss_patient = miss_reaction = miss_drug =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00e3471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150102/150102 [00:05<00:00, 25821.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022q4 file saved. with 150102 reports\n",
      "All data saved\n"
     ]
    }
   ],
   "source": [
    "        for report in tqdm(root.findall('safetyreport')):\n",
    "            \"\"\"Administrative Information\"\"\"\n",
    "#             report.find('').text\n",
    "            try:  # Mandatory Information: report_id\n",
    "                try:\n",
    "                    version = report.find('safetyreportversion').text\n",
    "                except:\n",
    "                    version = '1'\n",
    "                    \n",
    "                report_id = report.find('safetyreportid').text\n",
    "                \n",
    "                try:\n",
    "                    case_id = report.find('companynumb').text\n",
    "                except:\n",
    "                    case_id = '0'  # unknown case id\n",
    "                    \n",
    "                try:\n",
    "                    country = report.find('primarysource')[0].text\n",
    "                except:\n",
    "                    country = 'unknown'          \n",
    "\n",
    "                    \n",
    "                if country =='COUNTRY NOT SPECIFIED':\n",
    "                    country = 'unknown'\n",
    "                    \n",
    "                    \n",
    "                try:\n",
    "                    qualify = report.find('primarysource')[1].text\n",
    "                except:\n",
    "                    qualify = '6'  # the qualify is unknown\n",
    "                    \n",
    "#                 qualify = report.find('primarysource')[1].text\n",
    "                    \n",
    "                if qualify not in {'1', '2', '3', '4', '5', '6','7'}:\n",
    "                    qualify = '0'\n",
    "                                      \n",
    "                    \n",
    "                try:\n",
    "                    serious = report.find('serious').text\n",
    "                except:\n",
    "                    serious = '-1'\n",
    "                \n",
    "                try:\n",
    "                    s_1 = report.find('seriousnessdeath').text\n",
    "                except:\n",
    "                    s_1 = '0'\n",
    "                try:\n",
    "                    s_2 = report.find('seriousnesslifethreatening').text\n",
    "                except:\n",
    "                    s_2 = '0'\n",
    "                try:\n",
    "                    s_3 = report.find('seriousnesshospitalization').text\n",
    "                except:\n",
    "                    s_3 = '0'\n",
    "                try:\n",
    "                    s_4 = report.find('seriousnessdisabling').text\n",
    "                except:\n",
    "                    s_4 = '0'\n",
    "                try:\n",
    "                    s_5 = report.find('seriousnesscongenitalanomali').text\n",
    "                except:\n",
    "                    s_5 = '0'\n",
    "                try:\n",
    "                    s_6 = report.find('seriousnessother').text\n",
    "                except:\n",
    "                    s_6 = '0'\n",
    "                serious_subtype = [s_1, s_2, s_3, s_4, s_5, s_6]\n",
    "            except:\n",
    "                miss_admin +=1\n",
    "                continue\n",
    "\n",
    "            try:  # Optional information\n",
    "                # receivedate: Date when the report was the FIRST received\n",
    "                receivedateformat, receivedate = report.find('receivedateformat').text, report.find('receivedate').text\n",
    "                receivedate = date_normalize(receivedateformat, receivedate)\n",
    "            except:\n",
    "                receivedate = '0'\n",
    "            \n",
    "            try:\n",
    "                # receiptdate: Date of most RECENT report received\n",
    "                receiptdateformat, receiptdate = report.find('receiptdateformat').text, report.find('receiptdate').text\n",
    "                receiptdate = date_normalize(receiptdateformat, receiptdate)\n",
    "            except:\n",
    "                 receiptdate =  '0'\n",
    "\n",
    "            for patient in report.findall('patient'):\n",
    "                \"\"\"Demographic Information\"\"\"                \n",
    "                try:\n",
    "                    age = patient.find('patientonsetage').text\n",
    "                except:\n",
    "                    age = -1 # unknown age\n",
    "                try:\n",
    "                    ageunit = patient.find('patientonsetageunit').text\n",
    "                except:\n",
    "                    ageunit = '801' \n",
    "                # normalize age\n",
    "                try:\n",
    "                    age = int(age)  \n",
    "                    if age!= -1:\n",
    "                        if ageunit == '800':  # Decade \n",
    "                            age = '-1'\n",
    "                        elif ageunit == '801':  # Year\n",
    "                            age = age\n",
    "                        elif ageunit == '802':  # Month\n",
    "                            age = int(age/12)\n",
    "                        elif ageunit == '803':  # Week\n",
    "                            age = int(age/52)\n",
    "                        elif ageunit == '804':  # Day\n",
    "                            age = int(age/365)\n",
    "                        elif ageunit == '805':  # Hour\n",
    "                            age = int(age/(24*365))\n",
    "    #                     else:\n",
    "    #                         age = '-1'  # unknown age\n",
    "                except:\n",
    "                    age = -1\n",
    "                    \n",
    "                      \n",
    "                try:\n",
    "                    gender = patient.find('patientsex').text\n",
    "                except:\n",
    "                    gender = '0'\n",
    "                try:\n",
    "                    weight = patient.find('patientweight').text\n",
    "                except:\n",
    "                    weight = '0'\n",
    "                ## Nothing is mandatory\n",
    "#                 if age == -1 and gender== '0':  # Mandatory: if age & gender both missing, ignore this report.\n",
    "#                     miss_patient +=1\n",
    "#                     continue\n",
    "\n",
    "                reaction_list = []\n",
    "                for side_ in patient.findall('reaction'):\n",
    "                    try:  # outcome: 1-6, 6 levels in total\n",
    "                        try: \n",
    "                            PT_code = side_[0].text\n",
    "                        except:\n",
    "                            PT_code = '0'\n",
    "                        try:\n",
    "                            outcome = side_[2].text\n",
    "                        except:\n",
    "                            outcome = '6'\n",
    "                        try:\n",
    "                            PT = side_[1].text\n",
    "                        except:\n",
    "                            PT = 'none'\n",
    "                        reaction = [PT_code, PT, outcome]\n",
    "                    except:\n",
    "                        continue\n",
    "                    reaction_list.append(reaction) \n",
    "                if reaction_list.__len__() == 0:  # Mandatory condition: at least has one reaction\n",
    "                    miss_reaction += 1\n",
    "                    continue\n",
    "\n",
    "                drug_list = []\n",
    "                for drug_ in patient.findall('drug'):\n",
    "                    try:\n",
    "                        try:\n",
    "                            char =  drug_.find('drugcharacterization').text  # drugcharacterization: 1(suspect)/2(concomitant)/3(interacting)\n",
    "                        except:\n",
    "                            char = '0'\n",
    "                        try:\n",
    "                            product =  drug_.find('medicinalproduct').text  # drug brand\n",
    "                        except:\n",
    "                            product = 'none'\n",
    "                        \"\"\"Dosage are generally fixed according to the indication\"\"\"\n",
    "                        try: \n",
    "                            dorse, unit=  drug_.find('drugstructuredosagenumb').text, drug_.find('drugstructuredosageunit').text\n",
    "                            drugseparatedosagenumb, drugintervaldosageunitnumb, drugintervaldosagedefinition = \\\n",
    "                                drug_.find('drugseparatedosagenumb').text, drug_.find('drugintervaldosageunitnumb').text, \\\n",
    "                                drug_.find('drugintervaldosagedefinition').text\n",
    "                            form = drug_.find('drugdosageform').text  # tablet or capsule or sth \n",
    "                        except:\n",
    "                            dorse, unit, drugseparatedosagenumb,drugintervaldosageunitnumb, drugintervaldosagedefinition, form =\\\n",
    "                            '0', '0', '0','0','0', '0'\n",
    "                        try:\n",
    "                            route = drug_.find('drugadministrationroute').text\n",
    "                            if route == '048':\n",
    "                                route = '1'  # oral \n",
    "                            elif route == '061':\n",
    "                                route = '2'  # Topical\n",
    "                        except:\n",
    "                            route = '0'  # no information of route\n",
    "                        \n",
    "                        try:\n",
    "                            indication = drug_.find('drugindication').text  # indication (disease): super important\n",
    "                        except:\n",
    "                            indication = 'none'\n",
    "\n",
    "                        try:\n",
    "                            start_format, start_date = drug_.find('drugstartdateformat').text, drug_.find('drugstartdate').text\n",
    "                            start_date = date_normalize(start_format, start_date)\n",
    "                        except:\n",
    "                            start_date = '0'\n",
    "                        try:\n",
    "                            end_format, end_date = drug_.find('drugenddateformat').text, drug_.find('drugenddate').text\n",
    "                            end_date = date_normalize(end_format, end_date)\n",
    "                        except:\n",
    "                            try:\n",
    "                                end_date = receiptdate\n",
    "                            except:\n",
    "                                end_date = '0'\n",
    "                            \n",
    "                        try:\n",
    "                            action = drug_.find('actiondrug').text\n",
    "                        except:\n",
    "                            action = '5'\n",
    "                        try:\n",
    "                            additional = drug_.find('drugadditional').text\n",
    "                        except:\n",
    "                            additional = '3'\n",
    "                        try:\n",
    "                            readm = drug_.find('drugrecurreadministration').text\n",
    "                        except:\n",
    "                            readm = '3'\n",
    "                        try:\n",
    "                            substance = drug_.find('activesubstance')[0].text\n",
    "                        except:\n",
    "                            substance = 'none'\n",
    "                    except:  # Mandatory condition: if none of the above information is provided, ignore this report\n",
    "                        continue\n",
    "                    drug = [char, product, dorse, unit, drugseparatedosagenumb, drugintervaldosageunitnumb,\n",
    "                            drugintervaldosagedefinition, form, route, indication, start_date, end_date, action,\n",
    "                            readm, additional, substance]\n",
    "                    drug_list.append(drug)\n",
    "                if drug_list.__len__() ==0:\n",
    "                    miss_drug += 1\n",
    "                    continue\n",
    "\n",
    "                \"\"\"for patient_ID\"\"\"\n",
    "                dic[count] = [version, report_id, case_id, country, qualify, serious, \n",
    "                              s_1, s_2, s_3, s_4, s_5, s_6, \n",
    "                              receivedate, receiptdate,  \n",
    "                              age, gender, weight, reaction_list, drug_list]\n",
    "                count += 1\n",
    "\n",
    "        pickle.dump(dic, open('D:/Medra/faers_xml_2022Q4/XML/'+ qtr_name+'.pk', 'wb'))\n",
    "        \n",
    "        n_reports.append(len(dic))\n",
    "        print(qtr_name+' file saved. with', len(dic), 'reports')\n",
    "        miss_count[qtr_name] = [nmb_reports, miss_admin, miss_patient, miss_reaction, miss_drug]\n",
    "\n",
    "print ('All data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c374bd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150102"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of reports in 2019 Q4\n",
    "sep_2020 =pickle.load(open('D:/Medra/faers_xml_2022Q4/XML/2022q4.pk', 'rb'))\n",
    "len(sep_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d71966",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_pd = pd.DataFrame(sep_2020.values(), \n",
    "                          columns=['version','report_id','case_id','country','qualify','serious',\n",
    "                                   's1','s2','s3','s4','s5','s6','receivedate','receiptdate',\n",
    "                                   'age','gender','weight','SE','drugs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184189ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reports_pd.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c04c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:/Medra/faers_xml_2022Q4/XML/TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e202530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df['drugs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a56eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45b36615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drugs</th>\n",
       "      <td>[[1, ANTICOAGULANT SODIUM CITRATE, 0, 0, 0, 0,...</td>\n",
       "      <td>[[1, ENTRESTO, 0, 0, 0, 0, 0, 0, 1, Product us...</td>\n",
       "      <td>[[1, DILAUDID, 0, 0, 0, 0, 0, 0, 1, Product us...</td>\n",
       "      <td>[[1, RINVOQ, 0, 0, 0, 0, 0, 0, 1, Rheumatoid a...</td>\n",
       "      <td>[[1, LAGEVRIO, 0, 0, 0, 0, 0, 0, 1, COVID-19 t...</td>\n",
       "      <td>[[1, ANTICOAGULANT SODIUM CITRATE, 0, 0, 0, 0,...</td>\n",
       "      <td>[[1, SKYRIZI, 0, 0, 0, 0, 0, 0, 058, Crohn^s d...</td>\n",
       "      <td>[[1, TICAGRELOR, 0, 0, 0, 0, 0, 0, 1, Percutan...</td>\n",
       "      <td>[[1, BLEPHAMIDE, 1, 031, 1, 1, 804, Eye drops,...</td>\n",
       "      <td>[[1, JARDIANCE, 0, 0, 0, 0, 0, 0, 0, Product u...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[1, HUMIRA, 0, 0, 0, 0, 0, 0, 058, Rheumatoid...</td>\n",
       "      <td>[[1, PAXLOVID, 3, 032, 2, 1, 804, Tablet, 0, C...</td>\n",
       "      <td>[[1, FERRIPROX, 4.5, 012, 3, 1, 804, Oral solu...</td>\n",
       "      <td>[[1, PIQRAY, 300, 003, 1, 1, 804, Film-coated ...</td>\n",
       "      <td>[[1, ATEZOLIZUMAB, 1200, 003, 1, 3, 803, Infus...</td>\n",
       "      <td>[[1, RITUXIMAB, 0, 0, 0, 0, 0, 0, 042, Rheumat...</td>\n",
       "      <td>[[1, KESIMPTA, 20, 003, 1, 1, 803, Solution fo...</td>\n",
       "      <td>[[1, MITAPIVAT, 0, 0, 0, 0, 0, 0, 1, Anaemia o...</td>\n",
       "      <td>[[1, TYSABRI, 0, 0, 0, 0, 0, 0, 050, Multiple ...</td>\n",
       "      <td>[[1, MAKENA, 0, 0, 0, 0, 0, 0, 058, Premature ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0    \\\n",
       "drugs  [[1, ANTICOAGULANT SODIUM CITRATE, 0, 0, 0, 0,...   \n",
       "\n",
       "                                                     1    \\\n",
       "drugs  [[1, ENTRESTO, 0, 0, 0, 0, 0, 0, 1, Product us...   \n",
       "\n",
       "                                                     2    \\\n",
       "drugs  [[1, DILAUDID, 0, 0, 0, 0, 0, 0, 1, Product us...   \n",
       "\n",
       "                                                     3    \\\n",
       "drugs  [[1, RINVOQ, 0, 0, 0, 0, 0, 0, 1, Rheumatoid a...   \n",
       "\n",
       "                                                     4    \\\n",
       "drugs  [[1, LAGEVRIO, 0, 0, 0, 0, 0, 0, 1, COVID-19 t...   \n",
       "\n",
       "                                                     5    \\\n",
       "drugs  [[1, ANTICOAGULANT SODIUM CITRATE, 0, 0, 0, 0,...   \n",
       "\n",
       "                                                     6    \\\n",
       "drugs  [[1, SKYRIZI, 0, 0, 0, 0, 0, 0, 058, Crohn^s d...   \n",
       "\n",
       "                                                     7    \\\n",
       "drugs  [[1, TICAGRELOR, 0, 0, 0, 0, 0, 0, 1, Percutan...   \n",
       "\n",
       "                                                     8    \\\n",
       "drugs  [[1, BLEPHAMIDE, 1, 031, 1, 1, 804, Eye drops,...   \n",
       "\n",
       "                                                     9    ...  \\\n",
       "drugs  [[1, JARDIANCE, 0, 0, 0, 0, 0, 0, 0, Product u...  ...   \n",
       "\n",
       "                                                     990  \\\n",
       "drugs  [[1, HUMIRA, 0, 0, 0, 0, 0, 0, 058, Rheumatoid...   \n",
       "\n",
       "                                                     991  \\\n",
       "drugs  [[1, PAXLOVID, 3, 032, 2, 1, 804, Tablet, 0, C...   \n",
       "\n",
       "                                                     992  \\\n",
       "drugs  [[1, FERRIPROX, 4.5, 012, 3, 1, 804, Oral solu...   \n",
       "\n",
       "                                                     993  \\\n",
       "drugs  [[1, PIQRAY, 300, 003, 1, 1, 804, Film-coated ...   \n",
       "\n",
       "                                                     994  \\\n",
       "drugs  [[1, ATEZOLIZUMAB, 1200, 003, 1, 3, 803, Infus...   \n",
       "\n",
       "                                                     995  \\\n",
       "drugs  [[1, RITUXIMAB, 0, 0, 0, 0, 0, 0, 042, Rheumat...   \n",
       "\n",
       "                                                     996  \\\n",
       "drugs  [[1, KESIMPTA, 20, 003, 1, 1, 803, Solution fo...   \n",
       "\n",
       "                                                     997  \\\n",
       "drugs  [[1, MITAPIVAT, 0, 0, 0, 0, 0, 0, 1, Anaemia o...   \n",
       "\n",
       "                                                     998  \\\n",
       "drugs  [[1, TYSABRI, 0, 0, 0, 0, 0, 0, 050, Multiple ...   \n",
       "\n",
       "                                                     999  \n",
       "drugs  [[1, MAKENA, 0, 0, 0, 0, 0, 0, 058, Premature ...  \n",
       "\n",
       "[1 rows x 1000 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b79d80a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1000 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df2\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m df2\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5588\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   5587\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   5590\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\properties.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:769\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:214\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\base.py:69\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1000 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "df2.columns =['col1','col2','col3']\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
